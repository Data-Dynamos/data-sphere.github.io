"use strict";(self.webpackChunkdata_dynamos_github_io=self.webpackChunkdata_dynamos_github_io||[]).push([[1978],{3905:(e,t,r)=>{r.d(t,{Zo:()=>u,kt:()=>m});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var c=n.createContext({}),l=function(e){var t=n.useContext(c),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},u=function(e){var t=l(e.components);return n.createElement(c.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,c=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),d=l(r),h=a,m=d["".concat(c,".").concat(h)]||d[h]||p[h]||o;return r?n.createElement(m,i(i({ref:t},u),{},{components:r})):n.createElement(m,i({ref:t},u))}));function m(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=h;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[d]="string"==typeof e?e:a,i[1]=s;for(var l=2;l<o;l++)i[l]=r[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}h.displayName="MDXCreateElement"},4307:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var n=r(7462),a=(r(7294),r(3905));const o={sidebar_position:20,minutesToComplete:10},i="Driving Streaming in Production",s={unversionedId:"beyond-the-batch/streaming-technologies",id:"beyond-the-batch/streaming-technologies",title:"Driving Streaming in Production",description:"We've talked a lot about the theoretics (and even walked through some exercises) of Spark Streaming in this section. You might recall that many of our examples involved writing input to netcat, from which our Streaming Application picked up data. In production settings, we'll need to leverage tools that offer Pub/Sub architectures that are both addressable and can scale with lead. One popular tool is Kafka.",source:"@site/docs/beyond-the-batch/streaming-technologies.mdx",sourceDirName:"beyond-the-batch",slug:"/beyond-the-batch/streaming-technologies",permalink:"/data-dynamos.github.io/docs/beyond-the-batch/streaming-technologies",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/beyond-the-batch/streaming-technologies.mdx",tags:[],version:"current",sidebarPosition:20,frontMatter:{sidebar_position:20,minutesToComplete:10},sidebar:"tutorialSidebar",previous:{title:"Exercise: Streaming",permalink:"/data-dynamos.github.io/docs/beyond-the-batch/exercise-streaming"},next:{title:"Data Science Data Requirements",permalink:"/data-dynamos.github.io/docs/data-science-and-interpretability/data-science-data-requirements"}},c={},l=[],u={toc:l},d="wrapper";function p(e){let{components:t,...r}=e;return(0,a.kt)(d,(0,n.Z)({},u,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"driving-streaming-in-production"},"Driving Streaming in Production"),(0,a.kt)("p",null,"We've talked a lot about the theoretics (and even walked through some exercises) of Spark Streaming in this section. You might recall that many of our examples involved writing input to netcat, from which our Streaming Application picked up data. In production settings, we'll need to leverage tools that offer Pub/Sub architectures that are both addressable and can scale with lead. One popular tool is Kafka."),(0,a.kt)("div",{style:{textAlign:"center"}},(0,a.kt)("figure",{class:"video-container"},(0,a.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/PzPXRmVHMxI",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:"allowfullscreen"}))),(0,a.kt)("p",null,"There are other Cloud-native streaming technologies as well which offer similar capabilities. The next section ",(0,a.kt)("strong",{parentName:"p"},"Streaming Technologies")," (Bonus) gives an overview of these technologies in addition to a deep dive into Kafka topics (pun-intended, which you will understand after reading that section). The ",(0,a.kt)("strong",{parentName:"p"},"Streaming Technologies")," section is marked as ",(0,a.kt)("strong",{parentName:"p"},"Bonus")," because it requires a pre-requisite to multi-system cloud architectures, which isn't a pre-requisite to this training. We suggest going back to that section at a later time, but it remains in the narrative for the subset of our readers who want to venture in that direction."))}p.isMDXComponent=!0}}]);